{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io ,transform ,feature,measure,filters,morphology\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import glob\n",
    "from commonfunctions import *\n",
    "from Matcher import match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "staff_files = [\n",
    "    \"../resources/template/staff2.png\", \n",
    "    \"../resources/template/staff.png\"]\n",
    "quarter_files = [\n",
    "    \"../resources/template/quarter.png\", \n",
    "    \"../resources/template/solid-note.png\"]\n",
    "sharp_files = [\n",
    "    \"../resources/template/sharp.png\"]\n",
    "flat_files = [\n",
    "    \"../resources/template/flat-line.png\", \n",
    "    \"../resources/template/flat-space.png\" ]\n",
    "half_files = [\n",
    "    \"../resources/template/half-space.png\", \n",
    "    \"../resources/template/half-note-line.png\",\n",
    "    \"../resources/template/half-line.png\", \n",
    "    \"../resources/template/half-note-space.png\"]\n",
    "whole_files = [\n",
    "    \"../resources/template/whole-space.png\", \n",
    "    \"../resources/template/whole-note-line.png\",\n",
    "    \"../resources/template/whole-line.png\", \n",
    "    \"../resources/template/whole-note-space.png\"]\n",
    "time_files = [\n",
    "    \"../resources/template/24.jpg\",\n",
    "    \"../resources/template/34.jpg\",\n",
    "    \"../resources/template/44.jpg\",\n",
    "    \"../resources/template/68.jpg\",\n",
    "    \"../resources/template/common.jpg\"\n",
    "]\n",
    "sharp_files = [\n",
    "    \"../resources/template/f-sharp.png\",\n",
    "     \"../resources/template/sharp.png\",\n",
    "     \"../resources/template/sharp-line.png\",\n",
    "     \"../resources/template/sharp-space.png\"\n",
    "]\n",
    "clef_files = [\n",
    "    \"../resources/template/treble_1.jpg\",\n",
    "#     \"../resources/template/treble_2.jpg\",\n",
    "#     \"../resources/template/bass_1.jpg\"\n",
    "]\n",
    "rest_files = [\n",
    "    \"../resources/template/bar-rest.png\",\n",
    "    \"../resources/template/eighth_rest.jpg\",\n",
    "    \"../resources/template/quarter_rest.jpg\",\n",
    "    \"../resources/template/whole_rest.jpg\"\n",
    "\n",
    "    \n",
    "]\n",
    "\n",
    "#staff_imgs = [io.imread(staff_file) for staff_file in staff_files]\n",
    "quarter_imgs = [io.imread(quarter_file) for quarter_file in quarter_files]\n",
    "sharp_imgs = [io.imread(sharp_files) for sharp_files in sharp_files]\n",
    "flat_imgs = [io.imread(flat_file) for flat_file in flat_files]\n",
    "half_imgs = [io.imread(half_file) for half_file in half_files]\n",
    "whole_imgs = [io.imread(whole_file) for whole_file in whole_files]\n",
    "rest_imgs = [io.imread(rest_file) for rest_file in rest_files]\n",
    "clef_imgs = [io.imread(clef_file) for clef_file in clef_files]\n",
    "time_imgs = [io.imread(time_file) for time_file in time_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stafflines_positions = []\n",
    "# # Normalize stafflines\n",
    "# for i in range(5):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-b6010a5b1b68>:2: FutureWarning: Non RGB image conversion is now deprecated. For RGBA images, please use rgb2gray(rgba2rgb(rgb)) instead. In version 0.19, a ValueError will be raised if input image last dimension length is not 3.\n",
      "  img = rgb2gray(img)\n",
      "C:\\Users\\hp\\Desktop\\image\\Project\\Preprocessing\\Matcher.py:18: FutureWarning: The behavior of rgb2gray will change in scikit-image 0.19. Currently, rgb2gray allows 2D grayscale image to be passed as inputs and leaves them unmodified as outputs. Starting from version 0.19, 2D arrays will be treated as 1D images with 3 channels.\n",
      "  template= rgb2gray(template)\n"
     ]
    }
   ],
   "source": [
    "img = io.imread(\"download.png\")\n",
    "img = rgb2gray(img)\n",
    "best_locations, best_scale = match(img, clef_imgs,0.8)\n",
    "print(best_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(best_locations[i][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import io ,transform ,feature,measure,filters,morphology,transform\n",
    "# from skimage.color import rgb2gray\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as mpatches\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import glob\n",
    "# import sys\n",
    "# from commonfunctions import *\n",
    "# def match(img,templates):\n",
    "#         img_width, img_height = img.shape[0],img.shape[1]\n",
    "#         best_scale = 1\n",
    "#         maxvalue = -2000\n",
    "#         for template in templates:\n",
    "            \n",
    "#             template = rgb2gray(template)\n",
    "            \n",
    "#             for scale in [i/100.0 for i in range(50, 100, 3)]:\n",
    "\n",
    "#                 resizex = int(scale*template.shape[0])\n",
    "#                 resizey = int(scale*template.shape[1])\n",
    "#                 if ( resizex > img_width) or ( resizey > img_height):\n",
    "#                     continue\n",
    "                \n",
    "#                 template = transform.rescale(template, scale, anti_aliasing=False)\n",
    "#                 result = feature.match_template(img, template)\n",
    "#                 result = np.round(result,3)\n",
    "#                 #             result = np.where(result >= threshold)\n",
    "#                 if np.sum(result**2)  > maxvalue : \n",
    "#                     maxvalue = np.max(result)\n",
    "#         return maxvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
